{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May 28 06:52:18 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  TITAN Xp            Off  | 00000000:05:00.0 Off |                  N/A |\r\n",
      "| 25%   42C    P5    13W / 250W |     10MiB / 12194MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  TITAN Xp            Off  | 00000000:09:00.0 Off |                  N/A |\r\n",
      "| 23%   36C    P8     9W / 250W |     10MiB / 12196MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "# %env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as onp\n",
    "from functools import partial \n",
    "from collections import defaultdict\n",
    "\n",
    "import jax\n",
    "import jax.numpy as np\n",
    "from jax import grad, jit, vmap, value_and_grad\n",
    "from jax import random\n",
    "from jax.scipy.special import logsumexp\n",
    "from jax.experimental import optimizers\n",
    "from jax.experimental import stax\n",
    "from jax.experimental.stax import (BatchNorm, Conv, Dense, Flatten,\n",
    "                                   Relu, LogSoftmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules.utils\n",
    "import modules.datasets\n",
    "import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find GPU Devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GpuDevice(id=0), GpuDevice(id=1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = jax.devices('gpu')\n",
    "gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_key = random.PRNGKey(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1, 28, 28) (32, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "datahandler_key = 'pytorch' # 'pytorch', 'tensorflow'\n",
    "\n",
    "base_params = {\n",
    "    \"download_dir\" : config.download_dir,\n",
    "    \"dataset_name\" : \"MNIST\", # options: MNIST, CIFAR10\n",
    "    \"batch_size\"   : _BATCH_SIZE,\n",
    "    \"flatten_img\"  : False,\n",
    "    \"onehot_label\" : True\n",
    "}\n",
    "data_handler = modules.datasets.BuildDataHandler(datahandler_key, **base_params)\n",
    "\n",
    "for x, y in data_handler('train'):\n",
    "    print(x.shape, y.shape)\n",
    "    break\n",
    "    \n",
    "modules.utils.show_samples(data_handler, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model - Convolutional Neural Network\n",
    "\n",
    "We could continue in a similar low-level manner for building out CNNs as we have for the MLP, where we initialize kernels and setup the convolution operations using [`jax.lax.conv_general_dilated`](https://jax.readthedocs.io/en/test-docs/_autosummary/jax.lax.conv_general_dilated.html). However, as in Pytorch, Keras, and more recent versions of TF, JAX has an api for building models sequentially with abstracted layers (Conv, Dense, etc.):  [`jax.experimental.stax.serial`](https://jax.readthedocs.io/en/latest/jax.experimental.stax.html)\n",
    "\n",
    "Constructing the model this way yields two objects, the initialization function, `init_fxn`, and the update function, `update_fxn` (aka our feedforward pass). Read more [here](https://jax.readthedocs.io/en/latest/jax.experimental.stax.html#jax.experimental.stax.serial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (_BATCH_SIZE, *data_handler.img_dim)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_params(random_key, batch_size, num_classes, input_shape):\n",
    "    init_fxn, update_fxn = stax.serial(\n",
    "        Conv(32, (5, 5), (2, 2), padding=\"SAME\"),\n",
    "        BatchNorm(), Relu,\n",
    "        Conv(32, (5, 5), (2, 2), padding=\"SAME\"),\n",
    "        BatchNorm(), Relu,\n",
    "        Conv(10, (3, 3), (2, 2), padding=\"SAME\"),\n",
    "        BatchNorm(), Relu,\n",
    "        Conv(10, (3, 3), (2, 2), padding=\"SAME\"), Relu,\n",
    "        Flatten,\n",
    "        Dense(num_classes),\n",
    "        LogSoftmax\n",
    "    )\n",
    "\n",
    "    _, params = init_fxn(random_key, input_shape)\n",
    "    return update_fxn, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_fxn, params = initialize_params(random_key, _BATCH_SIZE, data_handler.num_classes, input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1, 28, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_imgs = onp.random.random(size=input_shape)\n",
    "test_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = update_fxn(params, test_imgs)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fxn(params, images, targets):\n",
    "    log_softmax = update_fxn(params, images)\n",
    "    return -np.sum(log_softmax * targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def update(i,params, x, y, opt_state):\n",
    "    \"\"\" Compute the gradient for a batch and update the parameters \"\"\"\n",
    "    value, grads = value_and_grad(loss_fxn)(params, x, y)\n",
    "    opt_state = opt_update(i, grads, opt_state)\n",
    "    return get_params(opt_state), opt_state, value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(params, data_handler, dataset_key):\n",
    "    \"\"\" Compute the accuracy for a provided dataloader \"\"\"\n",
    "    n_batches = data_handler.num_batches(dataset_key)\n",
    "    acc_total = 0\n",
    "    for batch_idx, (images, targets) in enumerate(data_handler(dataset_key)):\n",
    "        # Stdout\n",
    "        sys.stdout.write(f'\\r\\tEvaluating {dataset_key} set | Batch {batch_idx+1}/{n_batches}...')\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # Compute target class\n",
    "        target_class = np.argmax(targets, axis=1)\n",
    "        \n",
    "        # Model Inference\n",
    "        predicted_class = np.argmax(update_fxn(params, images), axis=1)\n",
    "        \n",
    "        # Aggregate\n",
    "        acc_total += np.sum(predicted_class == target_class)\n",
    "        \n",
    "    return acc_total / data_handler.size(dataset_key)\n",
    "\n",
    "def evaluate(step_i, params, data_handler, accuracies):\n",
    "    print(\"\\nEvaluation Phase.\")\n",
    "    for dataset_key in ['train', 'test']:\n",
    "        acc = accuracy(params, data_handler, dataset_key) \n",
    "        accuracies[dataset_key].append((step_i, acc))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training_loop(data_handler, n_epochs, opt_state, eval_freq):\n",
    "    \"\"\" Implements a learning loop over epochs. \"\"\"\n",
    "    # Metric containers\n",
    "    accuracies = defaultdict(list)\n",
    "    train_loss = []\n",
    "    \n",
    "    # Get the initial set of parameters \n",
    "    params = get_params(opt_state)\n",
    "    \n",
    "    # Init evaluation\n",
    "    evaluate(0, params, data_handler, accuracies)\n",
    "    \n",
    "    # Compute num train batches\n",
    "    n_train_batches = data_handler.num_batches('train')\n",
    "    \n",
    "    # Loop over the training epochs\n",
    "    try:\n",
    "        train_step_i = 0\n",
    "        for epoch_i in range(n_epochs):\n",
    "            epoch_loss = []\n",
    "            for batch_i, (data, target) in enumerate(data_handler('train')):\n",
    "                # Forward pass + Backprop\n",
    "                params, opt_state, loss_val = update(train_step_i, params, data, target, opt_state)\n",
    "                train_step_i += 1\n",
    "\n",
    "                # Update loss over epoch\n",
    "                epoch_loss.append(loss_val)\n",
    "\n",
    "                # Stdout\n",
    "                stdout_str = f\"\\r\\tTraining Phase | Epoch {epoch_i+1}/{n_epochs} -- \"\n",
    "                stdout_str += f\"Batch {batch_i}/{n_train_batches} -- Avg Epoch Loss: {onp.mean(epoch_loss):0.2f}...\"\n",
    "                sys.stdout.write(stdout_str)\n",
    "                sys.stdout.flush()\n",
    "\n",
    "            # Update loss over training\n",
    "            train_loss.append(epoch_loss)\n",
    "\n",
    "            # Evaluate\n",
    "            if (epoch_i+1) % eval_freq == 0:\n",
    "                evaluate(epoch_i, params, data_handler, accuracies)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nEnding early.\")\n",
    "    \n",
    "    return train_loss, accuracies, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "_LEARNING_RATE = 1e-3\n",
    "\n",
    "# Defining an optimizer in Jax\n",
    "opt_init, opt_update, get_params = optimizers.adam(_LEARNING_RATE)\n",
    "opt_state = opt_init(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Phase.\n",
      "\tEvaluating test set | Batch 313/313......\n",
      "\n",
      "\tTraining Phase | Epoch 1/5 -- Batch 1874/1875 -- Loss: 9.15....\n",
      "Evaluation Phase.\n",
      "\tEvaluating test set | Batch 313/313......\n",
      "\n",
      "\tTraining Phase | Epoch 2/5 -- Batch 1874/1875 -- Loss: 2.66...\n",
      "Evaluation Phase.\n",
      "\tEvaluating train set | Batch 239/1875..."
     ]
    }
   ],
   "source": [
    "_N_EPOCHS = 5\n",
    "_EVAL_FREQ = 1\n",
    "\n",
    "run_vals = run_training_loop(data_handler, _N_EPOCHS, opt_state, _EVAL_FREQ)\n",
    "train_loss, accuracies, params = run_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Loss and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules.utils.plot_metrics(train_loss, accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, accuracies = modules.utils.generate_samples(update_fxn, params, data_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules.utils.show_predictions(samples, accuracies, data_handler) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
