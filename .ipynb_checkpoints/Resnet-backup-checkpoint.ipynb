{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 27 06:54:58 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  TITAN Xp            Off  | 00000000:05:00.0 Off |                  N/A |\r\n",
      "| 39%   64C    P2    64W / 250W |  11737MiB / 12194MiB |     11%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  TITAN Xp            Off  | 00000000:09:00.0 Off |                  N/A |\r\n",
      "| 38%   59C    P2    65W / 250W |  11232MiB / 12196MiB |      3%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import numpy as onp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as np\n",
    "from jax import grad, jit, vmap, value_and_grad\n",
    "from jax import random\n",
    "from jax.scipy.special import logsumexp\n",
    "from jax.experimental import optimizers\n",
    "from jax.experimental import stax\n",
    "from jax.experimental.stax import (AvgPool, BatchNorm, Conv, Dense, FanInSum,\n",
    "                                   FanOut, Flatten, GeneralConv, Identity,\n",
    "                                   MaxPool, Relu, LogSoftmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvBlock(kernel_size, filters, strides=(2,2)):\n",
    "    ks = kernel_size\n",
    "    f1, f2, f3 = filters\n",
    "    \n",
    "    Main = stax.serial(\n",
    "        Conv(f1, (1,1), strides), BatchNorm(), Relu,\n",
    "        Conv(f2, (ks,ks), padding='SAME'), BatchNorm(), Relu,\n",
    "        Conv(f3, (1,1)), BatchNorm()\n",
    "    )\n",
    "    Shortcut = stax.serial(Conv(f3, (1,1), strides), BatchNorm())\n",
    "    \n",
    "    return stax.serial(FanOut(2), stax.parallel(Main, Shortcut), FanInSum, Relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IdentityBlock(kernel_size, filters):\n",
    "    ks = kernel_size\n",
    "    f1, f2 = filters\n",
    "    def make_main(input_shape):\n",
    "        return stax.serial(\n",
    "            Conv(f1, (1,1)), BatchNorm(), Relu,\n",
    "            Conv(f2, (ks,ks), padding='SAME'), BatchNorm(), Relu,\n",
    "            Conv(input_shape[3], (1,1)), BatchNorm()\n",
    "        )\n",
    "    Main = stax.shape_dependent(make_main)\n",
    "    return stax.serial(FanOut(2), stax.parallel(Main, Identity), FanInSum, Relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(num_classes):\n",
    "    return stax.serial(\n",
    "        GeneralConv(('NCHW', 'OIHW', 'NHWC'), 64, (7,7), (2,2), 'SAME'),\n",
    "        BatchNorm(), Relu, MaxPool((3,3), strides=(2,2)),\n",
    "        ConvBlock(3, [64, 64, 256], strides=(1,1)),\n",
    "        IdentityBlock(3, [64, 64]),\n",
    "        IdentityBlock(3, [64, 64]),\n",
    "        ConvBlock(3, [128, 128, 512]),\n",
    "        IdentityBlock(3, [128, 128]),\n",
    "        IdentityBlock(3, [128, 128]),\n",
    "        AvgPool((7,7)), Flatten, Dense(num_classes), LogSoftmax\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_key = random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_classes = 10\n",
    "input_shape = (batch_size, 3, 224, 224)\n",
    "step_size = 0.1\n",
    "num_steps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_fun, predict_fun = ResNet50(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, init_params = init_fun(rng_key, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(params, batch):\n",
    "    inputs, targets = batch\n",
    "    logits = predict_fun(params, inputs)\n",
    "    return -np.sum(logits*targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(params, batch):\n",
    "    inputs, targets = batch\n",
    "    target_class = np.argmax(targets, axis=-1)\n",
    "    predicted_class = np.argmax(predict_fun(params, inputs), axis=-1)\n",
    "    return np.mean(predicted_class == target_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synth_batches():\n",
    "    rng = onp.random.RandomState(0)\n",
    "    while True:\n",
    "        images = rng.rand(*input_shape).astype('float32')\n",
    "        labels = rng.randint(num_classes, size=(batch_size, 1))\n",
    "        onehot_labels = labels == onp.arange(num_classes)\n",
    "        yield images, onehot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_init, opt_update, get_params = optimizers.momentum(step_size, mass=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = synth_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def update(i, opt_state, batch):\n",
    "    params = get_params(opt_state)\n",
    "    return opt_update(i, grad(loss)(params, batch), opt_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_state = opt_init(init_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_steps):\n",
    "    sys.stdout.write(f'\\rEpoch {i+1}/{num_steps}...')\n",
    "    sys.stdout.flush()\n",
    "    opt_state = update(i, opt_state, next(batches))\n",
    "trained_params = get_params(opt_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
